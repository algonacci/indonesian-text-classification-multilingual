\chapter{Eksperimen dan Pembangunan Sistem}

\section{Lingkungan Eksperimen dan Pembangunan Sistem}

Eksperimen dilakukan di platform \href{https://www.kaggle.com}{Kaggle} dengan Kernel gratisnya. Bahasa Pemrograman yang digunakan adalah bahasa Python versi 3.6.6. Pada \textit{fine-tuning} layer terakhir digunakan CPU 1xSingle core hyper threaded Xeon Processors @2.3Ghz, 46MB Cache. Pada \textit{fine-tuning} penuh digunakan TPU v3-8. Eksperimen dikembangkan menggunakan kombinasi pustaka PyTorch \parencite{paszke2017automatic} dan TensorFlow \parencite{tensorflow2015}.

Untuk memastikan bahwasanya eksperimen \textit{reproducible} dan tidak memiliki faktor acak, semua opsi \textit{seed} baik di System, Python, hingga pustaka Pytorch ditetapkan agar hasil tidak berubah jika eksperimen dijalankan berkali-kali dengan kondisi yang sama.

\begin{lstlisting}[language=Python]
def set_seed():
    seed=1
    random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    torch.backends.cudnn.deterministic = True
\end{lstlisting}


\section{Eksperimen}
Eksperimen akan dilakukan dengan 2 model multilingual (XLM-R \& Multilingual BERT). Pada tiap eksperimen akan dilakukan variasi total data (500 / 1000 / 2500 / 5000 / 7500 / MAX) dan kelipatan bahasa asing pada skenario 3. Untuk konfigurasi model, callback berupa EarlyStopping dan ReduceLROnPlateau. Penggunaan callback EarlyStopping digunakanagar model tidak overfit. Sedangkan callback ReduceLROnPlateau digunakan untuk membantu model mencapai performa yang lebih baik. Semua eksperimen dijalankan hingga diberhentikan oleh callback EarlyStopping.


    \subsection{Hasil fine-tune layer terakhir}
        Berikut hasil eksperimen dengan model XLM-R: 
        \begin{enumerate}
            \item Analisis sentimen dengan data Prosa \\
            \begin{figure}[ht]
                \centering
                \includegraphics[width=0.75\textwidth]{resources/plot-head-prosa-xlmr.png}
                \caption{Plot antara F1-score dan kelipatan data bahasa Inggris pada berbagai total data di eksperimen data Prosa dengan model XLM-R.}
                \label{fig:plot_head_prosa_xlmr}
            \end{figure}
            Dapat dilihat pada Gambar \ref{fig:plot_head_prosa_xlmr}, performa analisis sentimen dataset Prosa sangat terbantu dengan penambahan data berbahasa Inggris. Di berbagai total data, penambahan bahasa Inggris menambah rata-rata F1-score sebesar 0.229. Penambahan performa terbesar diobservasi pada eksperimen dengan jumlah data yang sedikit. Performa model meningkat dari 0.734 pada skenario monolingual hingga mencapai 0.819 pada penambahan bahasa Inggris sebanya 7 kali lipat dari total bahasa Indonesianya.

            \item Analisis sentimen dengan data Trip Advisor \\
            \begin{figure}[ht]
                \centering
                \includegraphics[width=0.75\textwidth]{resources/plot-head-trip-xlmr.png}
                \caption{Plot antara F1-score dan kelipatan data bahasa Inggris pada berbagai total data di eksperimen data Trip Advisor dengan model XLM-R.}
                \label{fig:plot_head_trip_xlmr}
            \end{figure}
            Dapat dilihat pada Gambar \ref{fig:plot_head_trip_xlmr}, performa analisis sentimen dataset Trip Advisor terbantu dengan penambahan data berbahasa Inggris. Di berbagai total data, penambahan bahasa Inggris menambah rata-rata F1-score sebesar 0.107. Penambahan performa terbesar juga diobservasi pada eksperimen dengan jumlah data yang sedikit. Performa model meningkat dari 0.794 pada skenario monolingual hingga mencapai 0.823 pada penambahan bahasa Inggris sebanya 8 kali lipat dari total bahasa Indonesianya.

            \item Klasifikasi ujaran kebencian \& kasar \\
            \begin{figure}[ht]
                \centering
                \includegraphics[width=0.75\textwidth]{resources/plot-head-toxic-xlmr.png}
                \caption{Plot antara F1-score dan kelipatan data bahasa Inggris pada berbagai total data di eksperimen klasifikasi ujaran kebencian dengan model XLM-R.}
                \label{fig:plot_head_toxic_xlmr}
            \end{figure}
            Dapat dilihat pada Gambar \ref{fig:plot_head_toxic_xlmr}, performa klasifikasi ujaran kebencian tidak terlalu terbantu dengan penambahan data berbahasa Inggris. Meski performa model sempat terbantu, penambahan lebih banyak data bahasa Inggris menurunkan performa model.

        \end{enumerate}
        
        Melalui rangkaian eksperimen dengan model XLM-R di atas, dapat dilihat korelasi antara perbedaan performa skenario \textit{zero-shot} dan \textit{monolingual} dengan performa skenario \textit{multilingual learning}. Eksperimen sentimen analisis Prosa memiliki rata-rata perbedaan skenario 1 dan 2 sebesar 0.0005. Dengan perbedaan yang sangat kecil, penambahan bahasa Inggris sangat bermanfaat. Eksperimen sentimen analisis Trip Advisor memiliki rata-rata perbedaan skenario 1 dan 2 sebesar 0.044. Dengan perbedaan yang cukup besar, penambahan bahasa Inggris menjadi berkurang manfaatnya. Terakhir, eksperimen klasifikasi ujaran kebencian memiliki perbedaan skenario 1 dan 2 sebesar 0.093. Dengan perbedaan yang sangat besar, penambahan bahasa Inggris menjadi kurang bermanfaat dan bahkan menurunkan performa model.

        Berikut hasil eksperimen dengan model mBERT: 

        \begin{figure}[ht]
            \minipage{0.5\textwidth}
              \includegraphics[width=\linewidth]{resources/plot-head-prosa-mbert.png}
              \caption{Plot Prosa model mBERT}\label{fig:plot_head_prosa_mbert}
            \endminipage\hfill
            \minipage{0.5\textwidth}
              \includegraphics[width=\linewidth]{resources/plot-head-trip-mbert.png}
              \caption{Plot Trip model mBERT.}\label{fig:plot_head_trip_mbert}
            \endminipage
        \end{figure}

        \begin{figure}[ht]
            \centering
            \includegraphics[width=0.5\textwidth]{resources/plot-head-toxic-mbert.png}
            \caption{Plot ujaran kebencian model mBERT.}\label{fig:plot_head_toxic_mbert}
        \end{figure}

        Melalui rangkaian eksperimen dengan model mBERT di atas, dapat dilihat hal yang sama dengan eksperimen model XLM-R. Secara umum performa mBERT lebih lemah dibanding XLM-R. Selain itu, dapat kita lihat juga biasnya \textit{pretraining} mBERT ke bahasa Inggris. Di berbagai total data, performa \textit{zero-shot} lebih bagus dibanding pasangan \textit{monolingual}-nya. Hal ini dikarenakan dalam pelatihan mBERT memiliki jumlah data bahasa Inggris yang tidak proporsional dengan data lainnya. Berbeda dengan XLM-R yang melakukan \textit{sampling} pada tiap \textit{batch} pelatihannya untuk memastikan performa model proporsional antar bahasa.
            

    \subsection{Hasil fine-tune penuh}
        Berikut hasil eksperimen dengan model XLM-R pada analisis sentimen Prosa dan klasifikasi ujaran kebencian :

        \begin{figure}[ht]
            \minipage{0.5\textwidth}
              \includegraphics[width=\linewidth]{resources/plot-full-prosa-xlmr.png}
              \caption{Plot Prosa model XLM-R}\label{fig:plot_full_prosa_xlmr}
            \endminipage\hfill
            \minipage{0.5\textwidth}
              \includegraphics[width=\linewidth]{resources/plot-full-toxic-xlmr.png}
              \caption{Plot Ujaran kebencian model XLM-R.}\label{fig:plot_full_toxic_xlmr}
            \endminipage
        \end{figure}
        
        (baru sebagian eksperimen yang selesai dijalankan, plot di atas menggunakan seluruh data)
        
        Melalui sedikit eksperimen dengan model XLM-R di atas, dapat dilihat performa model XLM-R sangat bagus. Pada analisis sentimen dataset Prosa model berhasil memprediksi seluruh data tes dengan sempurna di skenario 3 dengan kelipatan bahasa Inggris 1.5. Pada klasifikasi ujaran kebencian model berhasil mencapai F1-Score 0.892 di skenario 3 dengan kelipatan bahasa Inggris 1.

    \subsection{Analisis hasil}
        
